{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yelpapi import YelpAPI\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir =  os.path.join(os.getcwd(),'Yelp_Data\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'Gxa0LqhgTU-G3sf9RuA_kt5dHTxgH-m5BNMdM-0TpN56PYRFdEnoj811SGiz9O2-a5TazMI5VpOzzBH91ZMX9p4PJ1K-ALQ0VSnuuL3t4Yt97lrV-3dBdNikmVC3X3Yx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_api = YelpAPI(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this part is going to be a pain. We can loop through this and get \n",
    "# results for each area, but there is a limit on the api request per day \n",
    "# per 30 days. Maybe just focus on major cities?\n",
    "\n",
    "businesses_location = 'Santa Barbara, CA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can play around with the limit and offset parameters \n",
    "# to control the number of results and what item to start the pull on\n",
    "search_results = yelp_api.search_query(term='Internet Service Providers',\n",
    "                                       location=businesses_location,\n",
    "                                      limit = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df = pd.DataFrame.from_dict(search_results['businesses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the phone, display_phone, transactions, is_closed, and image_url columns\n",
    "# we shouldn't need them\n",
    "unecessary_cols = ['phone', 'display_phone', 'transactions', 'is_closed', \n",
    "                   'image_url']\n",
    "\n",
    "\n",
    "business_df2 = business_df.drop(unecessary_cols,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through businesses\n",
    "business_reviews = dict()\n",
    "for iBiz, biz_id in enumerate(business_df2.loc[:,'id']):\n",
    "    business_name = business_df2['name'][iBiz]\n",
    "    \n",
    "    #can only get 3 reviews through yelp api\n",
    "    #BUT...we have the url...which means it should be easy to \"not legally\" scrape\n",
    "    business_reviews[business_name] = yelp_api.reviews_query(biz_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "businessRev_df = pd.DataFrame()\n",
    "\n",
    "for biz in business_reviews.keys():\n",
    "    \n",
    "    # temporary data frame we can use that will be appended to a master one later\n",
    "    temp_df = pd.DataFrame.from_dict(business_reviews[biz]['reviews'])\n",
    "    \n",
    "    temp_df = temp_df.drop('user',1)\n",
    "    \n",
    "    # add column for ISP provider\n",
    "    temp_df.insert(0,'ISP_name',biz)\n",
    "    \n",
    "    # add column for business id\n",
    "    temp_df.insert(1,'business_id',\n",
    "                   business_df[business_df['name'] == biz]['id'].item())\n",
    "    \n",
    "    temp_df.insert(6,'location',\n",
    "                       str(business_df2[business_df2['name'] == biz]['location'].item()['display_address']))\n",
    "    \n",
    "    temp_df = temp_df.rename(columns = {\"id\":\"rev_id\"})\n",
    "    \n",
    "    businessRev_df = businessRev_df.append(temp_df,ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "business_df2.to_csv(data_dir+'businesses.csv', index=False)\n",
    "businessRev_df.to_csv(data_dir+'businesses_reviews.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yelpapi import YelpAPI\n",
    "import pandas as pd\n",
    "\n",
    "def Yelp_ScrapeISP (api_key,city_names,business_data = None,\n",
    "                    business_reviews = None):\n",
    "    data_dir =  os.path.join(os.getcwd(),'Yelp_Data\\\\')\n",
    "\n",
    "    yelp_api = YelpAPI(api_key)\n",
    "    \n",
    "    all_business_df = pd.DataFrame()\n",
    "    all_reviews_df = pd.DataFrame()\n",
    "\n",
    "    for iCity in cities:\n",
    "        \n",
    "        # we can play around with the limit and offset parameters \n",
    "        # to control the number of results and what item to start the pull on\n",
    "        search_results = yelp_api.search_query(term = 'Internet Service Provides',\n",
    "                                               location = iCity, limit = 50)\n",
    "\n",
    "        business_df = pd.DataFrame.from_dict(search_results['businesses'])\n",
    "\n",
    "\n",
    "        # drop the phone, display_phone, transactions, is_closed, and image_url columns\n",
    "        # we shouldn't need them\n",
    "        unecessary_cols = ['phone', 'display_phone', 'transactions', 'is_closed','image_url']\n",
    "\n",
    "\n",
    "        business_df2 = business_df.drop(unecessary_cols,1)\n",
    "\n",
    "        #loop through businesses\n",
    "        reviews = dict()\n",
    "\n",
    "        reviews_df = pd.DataFrame()\n",
    "        for iBiz, biz_id in enumerate(business_df2.loc[:,'id']):\n",
    "            business_name = business_df2['name'][iBiz]\n",
    "\n",
    "            #can only get 3 reviews through yelp api\n",
    "            #BUT...we have the url...which means it should be easy to \"not legally\" scrape\n",
    "            reviews[business_name] = yelp_api.reviews_query(biz_id)\n",
    "\n",
    "            # temporary data frame we can use that will be appended to a master one later\n",
    "            temp_df = pd.DataFrame.from_dict(reviews[business_name]['reviews'])\n",
    "\n",
    "            temp_df = temp_df.drop('user',1)\n",
    "\n",
    "            # add column for ISP provider\n",
    "            temp_df.insert(0,'ISP_name',business_name)\n",
    "\n",
    "            # add column for business id\n",
    "            temp_df.insert(1,'business_id',biz_id)\n",
    "\n",
    "            # add column for business location\n",
    "            temp_df.insert(6,'location',\n",
    "                           str(business_df2[business_df2['id'] == biz_id]['location'].item()['display_address']))\n",
    "\n",
    "\n",
    "            temp_df = temp_df.rename(columns = {\"id\":\"rev_id\"})\n",
    "\n",
    "            reviews_df = reviews_df.append(temp_df,ignore_index = True)\n",
    "\n",
    "\n",
    "        all_business_df = all_business_df.append(business_df2, ignore_index=True)\n",
    "        all_reviews_df = all_reviews_df.append(reviews_df,ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    # if no previous files, just save the data. if previous files, append\n",
    "    if business_data == None and business_reviews == None:\n",
    "        all_business_df.to_csv(data_dir+'businesses.csv', index=False)\n",
    "        all_reviews_df.to_csv(data_dir+'businesses_reviews.csv', index = False)\n",
    "\n",
    "    else: #append data to previous loaded files\n",
    "\n",
    "        prev_business_df = pd.read_csv(data_dir+business_data)\n",
    "\n",
    "        prev_reviews_df = pd.read_csv(data_dir+business_reviews)\n",
    "\n",
    "        new_business_df = prev_business_df.append(all_business_df, ignore_index = True)\n",
    "        new_reviews_df = prev_reviews_df.append(all_reviews_df, ignore_index = True)\n",
    "\n",
    "        new_business_df.to_csv(data_dir+'businesses.csv', index=False)\n",
    "        new_reviews_df.to_csv(data_dir+'businesses_reviews.csv', index = False)\n",
    "\n",
    "#get the api key by creating an account on yelp and then clicking on Create App. Fill out\n",
    "#form and it will generate a key for you.\n",
    "api_key = 'Gxa0LqhgTU-G3sf9RuA_kt5dHTxgH-m5BNMdM-0TpN56PYRFdEnoj811SGiz9O2-a5TazMI5VpOzzBH91ZMX9p4PJ1K-ALQ0VSnuuL3t4Yt97lrV-3dBdNikmVC3X3Yx'\n",
    "cities = ['Santa Barbara, CA','Los Angeles, CA', 'Santa Clarita, CA', 'Walnut, CA']\n",
    "\n",
    "business_dataFile = 'businesses.csv'\n",
    "business_reviewsFile = 'businesses_reviews.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yelp_ScrapeISP(api_key,cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

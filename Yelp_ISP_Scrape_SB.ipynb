{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape data using the yelp api\n",
    "#!pip install yelpapi\n",
    "\n",
    "from yelpapi import YelpAPI\n",
    "import pandas as pd\n",
    "import os \n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Yelp_ScrapeISP(api_key, city_names, business_data, business_reviews):\n",
    "    \"\"\"\n",
    "\t====================================================================\n",
    "\tVersion: 1.0.0\n",
    "\tDate: Tue 24 Nov 2020\n",
    "\tPurposes: Search and save yelp data about internet service providers\n",
    "\twithin a region. \n",
    "\tInput:\n",
    "\t\tRequired:\n",
    "\t\t\tapi_key = Api key assigned by yelp fusion\n",
    "\t\t\tcity_names = List of locations for internet service providers\n",
    "\t\tOptional:\n",
    "\t\t\tbusiness_data = .csv file containing data from previous searches\n",
    "\t\t\tbusiness_reviews = .csv file containing reviews of businesses from\n",
    "\t\t\t\t\t\t\t\tprevious searches\n",
    "\tOutput:\n",
    "\t\t'businesses.csv' containing information about internet \n",
    "\t\t\tservice providers\n",
    "\t\t'businesses_reviews.csv' containing reviews of internet service\n",
    "\t\t\tproviders in the businesses.csv file\n",
    "\t\t'cities_list.csv' list of previous cities that have been searched.\n",
    "\t\t\tData will only be extracted for cities that have not been\n",
    "\t\t\tpreviously searched.\n",
    "\t\n",
    "\tExample: \n",
    "\tcities = ['Santa Barbara, CA','Los Angeles, CA','New York, NY']\n",
    "\tapi_key = XIXIXIXLXJO\n",
    "\tYelp_ScrapeISP(api_key,cities)\n",
    "\tAuthor: Jordan Garrett\n",
    "\tjordangarrett@ucsb.edu\n",
    "\t====================================================================\n",
    "\t\"\"\"\n",
    "    data_dir =  os.path.join(os.getcwd(),'Yelp_Data/')\n",
    "\n",
    "    \n",
    "    #check to see if any cities in the list have previously been searched\n",
    "    if os.path.exists(data_dir+'cities_list.csv'):\n",
    "    \tprev_cities = pickle.load(open(data_dir+'cities_list.csv','rb'))\n",
    "    \tcity_names = [city for city in city_names if city not in prev_cities]\n",
    "\n",
    "    if city_names:\n",
    "    \tprint(f'Searching Cities: {city_names}')\n",
    "    else:\n",
    "    \tprint('All cities have already been searched')\n",
    "    \treturn\n",
    "\n",
    "\n",
    "    yelp_api = YelpAPI(api_key)\n",
    "    \n",
    "    all_business_df = pd.DataFrame()\n",
    "    all_reviews_df = pd.DataFrame()\n",
    "\n",
    "    for iCity in city_names:\n",
    "        \n",
    "        # we can play around with the limit and offset parameters \n",
    "        # to control the number of results and what item to start the pull on\n",
    "        \n",
    "        search_results = yelp_api.search_query(term = 'Internet Service Provides',\n",
    "                                               location = iCity, limit = 50)\n",
    "        time.sleep(3)\n",
    "\n",
    "        business_df = pd.DataFrame.from_dict(search_results['businesses'])\n",
    "\n",
    "\n",
    "        # drop the phone, display_phone, transactions, is_closed, and image_url columns\n",
    "        # we shouldn't need them\n",
    "        unecessary_cols = ['phone', 'display_phone', 'transactions', 'is_closed','image_url']\n",
    "\n",
    "\n",
    "        business_df2 = business_df.drop(unecessary_cols,1)\n",
    "\n",
    "        #loop through businesses\n",
    "        reviews = dict()\n",
    "\n",
    "        reviews_df = pd.DataFrame()\n",
    "        for iBiz, biz_id in enumerate(business_df2.loc[:,'id']):\n",
    "            business_name = business_df2['name'][iBiz]\n",
    "\n",
    "            #can only get 3 reviews through yelp api\n",
    "            #BUT...we have the url...which means it should be easy to \"not legally\" scrape\n",
    "            reviews[business_name] = yelp_api.reviews_query(biz_id)\n",
    "            \n",
    "            time.sleep(3)\n",
    "\n",
    "            # temporary data frame we can use that will be appended to a master one later\n",
    "            temp_df = pd.DataFrame.from_dict(reviews[business_name]['reviews'])\n",
    "\n",
    "            temp_df = temp_df.drop('user',1)\n",
    "\n",
    "            # add column for ISP provider\n",
    "            temp_df.insert(0,'ISP_name',business_name)\n",
    "\n",
    "            # add column for business id\n",
    "            temp_df.insert(1,'business_id',biz_id)\n",
    "\n",
    "            # add column for business location\n",
    "            temp_df.insert(6,'location',\n",
    "                           str(business_df2[business_df2['id'] == biz_id]['location'].item()['display_address']))\n",
    "\n",
    "\n",
    "            temp_df = temp_df.rename(columns = {\"id\":\"rev_id\"})\n",
    "\n",
    "            reviews_df = reviews_df.append(temp_df,ignore_index = True)\n",
    "\n",
    "\n",
    "        all_business_df = all_business_df.append(business_df2, ignore_index=True)\n",
    "        all_reviews_df = all_reviews_df.append(reviews_df,ignore_index=True)\n",
    "\n",
    "    # Save data\n",
    "    # if no previous files, just save the data. if previous files, append    \n",
    "    if business_data == None and business_reviews == None:\n",
    "        all_business_df.to_csv(data_dir+'businesses.csv', index=False)\n",
    "        all_reviews_df.to_csv(data_dir+'businesses_reviews.csv', index = False)\n",
    "\n",
    "    else: #append data to previous loaded files\n",
    "        prev_business_df = pd.read_csv(data_dir+business_data)\n",
    "\n",
    "        prev_reviews_df = pd.read_csv(data_dir+business_reviews)\n",
    "\n",
    "        new_business_df = prev_business_df.append(all_business_df, ignore_index = True)\n",
    "        new_reviews_df = prev_reviews_df.append(all_reviews_df, ignore_index = True)\n",
    "\n",
    "        new_business_df.to_csv(data_dir+'businesses.csv', index=False)\n",
    "        new_reviews_df.to_csv(data_dir+'businesses_reviews.csv', index = False)\n",
    "\n",
    "\n",
    "    # Save previous cities to ensure that we aren't looking at cities previously searched\n",
    "    pickle.dump(city_names, open(data_dir+\"cities_list.csv\", \"wb\"))\n",
    "\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#\tYelp_ScrapeISP(api_key,cities,\n",
    "#\t\tbusiness_dataFile,business_reviewsFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the api key by creating an account on yelp and then clicking on Create App. Fill out\n",
    "#form and it will generate a key for you.\n",
    "api_key = \""\n",
    "\n",
    "#cities = ['Los Angeles, CA','Santa Barbara, CA','Walnut, CA',\n",
    "#'Santa Clarita, CA','Pomona,CA','Fresno,CA']\n",
    "\n",
    "cities = pd.read_csv(\"cal_cities_lat_long.csv\")\n",
    "cities[\"Name\"] = cities[\"Name\"] + \", CA\"\n",
    "\n",
    "first_half_cities = cities[0:round(len(cities)/2)]\n",
    "\n",
    "second_half_cities = cities[round(len(cities)/2):len(cities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Marysville, CA',\n",
       " 'Maywood, CA',\n",
       " 'McFarland, CA',\n",
       " 'Mendota, CA',\n",
       " 'Menifee, CA']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need to chunk it\n",
    "# does not include number on right side, can just change right side too since it will search all terms\n",
    "next_chunk = second_half_cities.Name.to_list()[10:15] \n",
    "next_chunk\n",
    "\n",
    "#len(second_half_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching Cities: ['Maricopa, CA', 'Marina, CA', 'Martinez, CA']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:98: FutureWarning: `item` has been deprecated and will be removed in a future version\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "#Yelp_ScrapeISP(api_key, second_half_cities.Name.to_list()[0:2], None, None)\n",
    "Yelp_ScrapeISP(api_key, next_chunk, \"businesses.csv\", \"businesses_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir =  os.path.join(os.getcwd(),'Yelp_Data/')\n",
    "#prev_cities = pickle.load(open(data_dir+'cities_list.csv','rb'))\n",
    "\n",
    "#city_names = second_half_cities.Name.to_list()[2:4]\n",
    "#city_names = [city for city in city_names if city not in prev_cities]\n",
    "#city_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
